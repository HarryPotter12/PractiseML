{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AML Ass1 Q4 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarryPotter12/PractiseML/blob/master/AML_Ass1_Q4_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZOlf5GncS7P"
      },
      "source": [
        "#### 4. Decision Trees: (13 marks) \n",
        "In this question, you will use the Wine dataset, a popular dataset to evaluate classification algorithms. The classification task is to determine, based on various parameters, whether a wine quality is over 7. The dataset has already been preprocessed to convert this into a binary classification problem (scores less than 7 belong to the “zero” class, and scores greater than or equal to 7 belong to the “one” class). Each line describes a wine, using 12 columns: the first 11 describe the wine’s characteristics (details), and the last column is a ground truth label for the quality of the wine (0/1). You must not use the last column as an input feature when you classify the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9B92gSQcnYs"
      },
      "source": [
        "#### (a) (5 marks) Decision Tree Implementation: \n",
        "Implement your own version of the decision tree using binary univariate split, entropy and information gain. (If you are using Python, you can use the skeleton code provided. For this question, use of libraries like sklearn is not permitted; you can use numpy or pandas as required though.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE2G5Aa336f-"
      },
      "source": [
        "import csv\n",
        "import math\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqm6POVL4c7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86ff756-7265-4911-b688-81f002e7dd71"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuGJ8BPIcY-t"
      },
      "source": [
        "# Enter You Name Here\n",
        "myname = \"Anuran-Banerjee-\" # or \"Doe-Jane-\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dApkSZCEcVZY"
      },
      "source": [
        "# Implement your decision tree below\n",
        "class DecisionTree():\n",
        "    tree = {}\n",
        "\n",
        "    def learn(self, training_set, attributes, target):\n",
        "        # implement this function\n",
        "        self.tree = build_tree(training_set, attributes, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn01oa_PRVk-"
      },
      "source": [
        "# Class Node which will be used while classify a test-instance using the tree which was built earlier\n",
        "class Node():\n",
        "    value = \"\"\n",
        "    children = []\n",
        "\n",
        "    def __init__(self, val, dictionary):\n",
        "        self.value = val\n",
        "        if (isinstance(dictionary, dict)):\n",
        "            #self.children = dictionary.keys()\n",
        "            self.children = list(dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB_LmswoRYMq"
      },
      "source": [
        "# Majority Function which tells which class has more entries in given data-set\n",
        "def majorClass(attributes, data, target):\n",
        "\n",
        "    freq = {}\n",
        "    index = attributes.index(target)\n",
        "\n",
        "    for tuple in data:\n",
        "        #if (freq.has_key(tuple[index])):\n",
        "        if tuple[index] in freq:\n",
        "            freq[tuple[index]] += 1 \n",
        "        else:\n",
        "            freq[tuple[index]] = 1\n",
        "\n",
        "    max = 0\n",
        "    major = \"\"\n",
        "\n",
        "    #for key in freq.keys():\n",
        "    for key in list(freq):\n",
        "        if freq[key]>max:\n",
        "            max = freq[key]\n",
        "            major = key\n",
        "\n",
        "    return major"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8o1aSDzRcVW"
      },
      "source": [
        "# Calculates the entropy of the data given the target attribute\n",
        "def entropy(attributes, data, targetAttr):\n",
        "\n",
        "    freq = {}\n",
        "    dataEntropy = 0.0\n",
        "\n",
        "    i = 0\n",
        "    for entry in attributes:\n",
        "        if (targetAttr == entry):\n",
        "            break\n",
        "        i = i + 1\n",
        "\n",
        "    i = i - 1\n",
        "\n",
        "    for entry in data:\n",
        "        #if (freq.has_key(entry[i])):\n",
        "        if entry[i] in freq:\n",
        "            freq[entry[i]] += 1.0\n",
        "        else:\n",
        "            freq[entry[i]]  = 1.0\n",
        "\n",
        "    for freq in freq.values():\n",
        "        dataEntropy += (-freq/len(data)) * math.log(freq/len(data), 2) \n",
        "        \n",
        "    return dataEntropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mCzqmUHRe4y"
      },
      "source": [
        "# Calculates the information gain (reduction in entropy) in the data when a particular attribute is chosen for splitting the data.\n",
        "def info_gain(attributes, data, attr, targetAttr):\n",
        "\n",
        "    freq = {}\n",
        "    subsetEntropy = 0.0\n",
        "    i = attributes.index(attr)\n",
        "\n",
        "    for entry in data:\n",
        "        #if (freq.has_key(entry[i])):\n",
        "        if entry[i] in freq:\n",
        "            freq[entry[i]] += 1.0\n",
        "        else:\n",
        "            freq[entry[i]]  = 1.0\n",
        "\n",
        "    #for val in freq.keys():\n",
        "    for val in list(freq):\n",
        "        valProb        = freq[val] / sum(freq.values())\n",
        "        dataSubset     = [entry for entry in data if entry[i] == val]\n",
        "        subsetEntropy += valProb * entropy(attributes, dataSubset, targetAttr)\n",
        "\n",
        "    return (entropy(attributes, data, targetAttr) - subsetEntropy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO1-GmyARg_s"
      },
      "source": [
        "# This function chooses the attribute among the remaining attributes which has the maximum information gain.\n",
        "def attr_choose(data, attributes, target):\n",
        "\n",
        "    best = attributes[0]\n",
        "    maxGain = 0;\n",
        "\n",
        "    for attr in attributes:\n",
        "        newGain = info_gain(attributes, data, attr, target) \n",
        "        if newGain>maxGain:\n",
        "            maxGain = newGain\n",
        "            best = attr\n",
        "\n",
        "    return best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0-qINXRRjKB"
      },
      "source": [
        "# This function will get unique values for that particular attribute from the given data\n",
        "def get_values(data, attributes, attr):\n",
        "\n",
        "    index = attributes.index(attr)\n",
        "    values = []\n",
        "\n",
        "    for entry in data:\n",
        "        if entry[index] not in values:\n",
        "            values.append(entry[index])\n",
        "\n",
        "    return values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYiJ_5ktRlG9"
      },
      "source": [
        "# This function will get all the rows of the data where the chosen \"best\" attribute has a value \"val\"\n",
        "def get_data(data, attributes, best, val):\n",
        "\n",
        "    new_data = [[]]\n",
        "    index = attributes.index(best)\n",
        "\n",
        "    for entry in data:\n",
        "        if (entry[index] == val):\n",
        "            newEntry = []\n",
        "            for i in range(0,len(entry)):\n",
        "                if(i != index):\n",
        "                    newEntry.append(entry[i])\n",
        "            new_data.append(newEntry)\n",
        "\n",
        "    new_data.remove([])    \n",
        "    return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy0JLlCwRm9s"
      },
      "source": [
        "# This function is used to build the decision tree using the given data, attributes and the target attributes. It returns the decision tree in the end.\n",
        "def build_tree(data, attributes, target):\n",
        "\n",
        "    data = data[:]\n",
        "    vals = [record[attributes.index(target)] for record in data]\n",
        "    default = majorClass(attributes, data, target)\n",
        "\n",
        "    if not data or (len(attributes) - 1) <= 0:\n",
        "        return default\n",
        "    elif vals.count(vals[0]) == len(vals):\n",
        "        return vals[0]\n",
        "    else:\n",
        "        best = attr_choose(data, attributes, target)\n",
        "        tree = {best:{}}\n",
        "    \n",
        "        for val in get_values(data, attributes, best):\n",
        "            new_data = get_data(data, attributes, best, val)\n",
        "            newAttr = attributes[:]\n",
        "            newAttr.remove(best)\n",
        "            subtree = build_tree(new_data, newAttr, target)\n",
        "            tree[best][val] = subtree\n",
        "    \n",
        "    return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvXw--7DRwQM"
      },
      "source": [
        "def run_decision_tree():\n",
        "\n",
        "    # Load data set\n",
        "    with open(\"/content/gdrive/My Drive/Datasets/wine-dataset.csv\") as f:\n",
        "        attrib = next(f, None)\n",
        "        data = [tuple(line) for line in csv.reader(f, delimiter=\",\")]\n",
        "    print(\"Number of records: %d\" % len(data))\n",
        "    \n",
        "    attributes = attrib.split(\",\")\n",
        "    target = attributes[-1]\n",
        "    # Split training/test sets\n",
        "    # You need to modify the following code for cross validation.\n",
        "    K = 10\n",
        "    training_set = [x for i, x in enumerate(data) if i % K != 7]\n",
        "    test_set = [x for i, x in enumerate(data) if i % K == 7]\n",
        "    \n",
        "    tree = DecisionTree()\n",
        "    # Construct a tree using training set\n",
        "    tree.learn( training_set, attributes , target )\n",
        "\n",
        "    # Classify the test set using the tree we just constructed\n",
        "    results = []\n",
        "    # for instance in test_set:\n",
        "    #     result = tree.classify( instance[:-1] )\n",
        "    #     results.append( result == instance[-1])\n",
        "\n",
        "    for instance in test_set:\n",
        "        tempDict = tree.tree.copy()\n",
        "        result = \"\"\n",
        "        while(isinstance(tempDict, dict)):\n",
        "            #root = Node(tempDict.keys()[0], tempDict[tempDict.keys()[0]])\n",
        "            root = Node(list(tempDict)[0], tempDict[list(tempDict)[0]])\n",
        "            #tempDict = tempDict[tempDict.keys()[0]]\n",
        "            tempDict = tempDict[list(tempDict)[0]]\n",
        "            index = attributes.index(root.value)\n",
        "            value = instance[index]\n",
        "            #if(value in tempDict.keys()):\n",
        "            if(value in list(tempDict)):\n",
        "                child = Node(value, tempDict[value])\n",
        "                result = tempDict[value]\n",
        "                tempDict = tempDict[value]\n",
        "            else:\n",
        "                result = \"Null\"\n",
        "                break\n",
        "        if result != \"Null\":\n",
        "            results.append(result == instance[-1])\n",
        "            \n",
        "    # Accuracy\n",
        "    accuracy = float(results.count(True))/float(len(results))\n",
        "    print(\"=== Initial Implementation ===\")\n",
        "    print(\"Accuracy: %.4f\" % accuracy)\n",
        "    \n",
        "    # Writing results to a file \n",
        "    f = open(\"/content/gdrive/My Drive/\"+myname+\"result.txt\", \"w\")\n",
        "    f.write(\"=== Initial Implementation === \\n\")\n",
        "    f.write(\"Accuracy: %.4f\\n\" % accuracy)\n",
        "    f.close()\n",
        "    \n",
        "    K = 10\n",
        "    acc = []\n",
        "    for k in range(K):\n",
        "        # random.shuffle(data)\n",
        "        training_set = [x for i, x in enumerate(data) if i % K != k]\n",
        "        test_set = [x for i, x in enumerate(data) if i % K == k]\n",
        "        tree = DecisionTree()\n",
        "        tree.learn( training_set, attributes, target )\n",
        "        results = []\n",
        "\n",
        "        for entry in test_set:\n",
        "            tempDict = tree.tree.copy()\n",
        "            result = \"\"\n",
        "            while(isinstance(tempDict, dict)):\n",
        "                #root = Node(tempDict.keys()[0], tempDict[tempDict.keys()[0]])\n",
        "                root = Node(list(tempDict)[0], tempDict[list(tempDict)[0]])\n",
        "                #tempDict = tempDict[tempDict.keys()[0]]\n",
        "                tempDict = tempDict[list(tempDict)[0]]\n",
        "                index = attributes.index(root.value)\n",
        "                value = entry[index]\n",
        "                #if(value in tempDict.keys()):\n",
        "                if(value in list(tempDict)):\n",
        "                    child = Node(value, tempDict[value])\n",
        "                    result = tempDict[value]\n",
        "                    tempDict = tempDict[value]\n",
        "                else:\n",
        "                    result = \"Null\"\n",
        "                    break\n",
        "            if result != \"Null\":\n",
        "                results.append(result == entry[-1])\n",
        "\n",
        "        accuracy = float(results.count(True))/float(len(results))\n",
        "        acc.append(accuracy)\n",
        "\n",
        "    avg_acc = sum(acc)/len(acc)\n",
        "    print(\"=== After Cross-validation ===\")\n",
        "    print(\"Average accuracy: %.4f\" % avg_acc)    \n",
        "\n",
        "    # Writing results to a file\n",
        "    f = open(\"/content/gdrive/My Drive/\"+myname+\"result.txt\", \"a\")\n",
        "    f.write(\"=== After Cross-validation === \\n\")\n",
        "    f.write(\"Average accuracy: %.4f\\n\" % avg_acc)\n",
        "    f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o81c8jR6cn58"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  run_decision_tree()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCa47KgVczd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3058a2d2-eed2-4341-8da7-5e2bbc790db6"
      },
      "source": [
        "run_decision_tree()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of records: 4898\n",
            "=== Initial Implementation ===\n",
            "Accuracy: 0.8910\n",
            "=== After Cross-validation ===\n",
            "Average accuracy: 0.9015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrSCOCrLg0XO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}